{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS6301 IOT Project 2\n",
    "\n",
    "## Fault Diagnostic Tool (Read Side)\n",
    "\n",
    "This side of the application ingests data from the data generator and ensures it's being imported into the database correctly.\n",
    "\n",
    "### Before Running this Notebook\n",
    "1. Ensure the database is running on your localhost. Using docker-compose file in the root of the project directory we can start the InfluxDB with the following command from the root directory:\n",
    "`dc up timeseriesdb`\n",
    "\n",
    "2. Turn on the data generator with the following command from the \"iot\" directory.\n",
    "`java -jar datagen-2.2-SNAPSHOT.jar -offline`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: influxdb in /Users/daytonpe/anaconda3/lib/python3.7/site-packages (5.2.3)\n",
      "Requirement already satisfied: pytz in /Users/daytonpe/anaconda3/lib/python3.7/site-packages (from influxdb) (2019.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/daytonpe/anaconda3/lib/python3.7/site-packages (from influxdb) (1.14.0)\n",
      "Requirement already satisfied: requests>=2.17.0 in /Users/daytonpe/anaconda3/lib/python3.7/site-packages (from influxdb) (2.23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.0 in /Users/daytonpe/anaconda3/lib/python3.7/site-packages (from influxdb) (2.8.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/daytonpe/anaconda3/lib/python3.7/site-packages (from requests>=2.17.0->influxdb) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/daytonpe/anaconda3/lib/python3.7/site-packages (from requests>=2.17.0->influxdb) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/daytonpe/anaconda3/lib/python3.7/site-packages (from requests>=2.17.0->influxdb) (2019.11.28)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/daytonpe/anaconda3/lib/python3.7/site-packages (from requests>=2.17.0->influxdb) (2.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install influxdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from influxdb import InfluxDBClient\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InfluxDBClient(host='localhost', port=8086, username='admin', password='password')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': '_internal'}, {'name': 'timeseriesdb'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_list_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest Data (Example: Offline Data)\n",
    "In this section we will ingest the data from a text file for exploration purposes. Normally this data would be ingesteddirctly from the Java data generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.drop_database('timeseriesdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.create_database('timeseriesdb')\n",
    "client.switch_database('timeseriesdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/offline-train.txt', 'r')\n",
    "lines = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement = 'gear_metrics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = json.loads(lines[0])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for line in lines:\n",
    "    json_line = json.loads(line)\n",
    "    # Form: 'gear_metrics,metric=offline label=0,sr=97656.0,rate=25.0,gs=0.8407559,load=270.0,timestamp=0'\n",
    "    data.append(\"{},metric={} label={},sr={},rate={},gs={},load={},timestamp={}\".format(measurement, json_line['metric'], json_line['label'], json_line['sr'], json_line['rate'], json_line['gs'], json_line['load'], json_line['timestamp']))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.write_points(data, database='timeseriesdb', time_precision='ms', batch_size=100, protocol='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = client.query('SELECT label, sr, rate, gs, load, timestamp, time FROM timeseriesdb.autogen.gear_metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results.raw['series'][0]['values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.raw['series'][0]['values'][0:10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "points = results.get_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for point in points:\n",
    "    print(\"Time: {}, gs: {}\".format(point['timestamp'], point['gs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline Training\n",
    "In this section we visualize the data ingested from the Java data generator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv():\n",
    "\tfile = open('data/offline-train-BIG.txt','r')\n",
    "\n",
    "\twith open('data/data.csv','w') as fcsv:\n",
    "\t\tfcsv.write(\"Metric,Timestamp,Label,SR,Rate,GR,Load\\n\")\n",
    "\t\tfor f in file:\n",
    "\t\t\tl= f.split(',')\n",
    "\n",
    "\t\t\tm = l[0].split(\":\")[1].split('\"')[1]\t\n",
    "\t\t\t#metric.append(m)\n",
    "\n",
    "\t\t\tt =l[1].split(\":\")[1]\n",
    "\t\t\t#timestamp.append(t)\n",
    "\n",
    "\t\t\tla =l[2].split(\":\")[1]\n",
    "\t\t\t#label.append(la)\n",
    "\n",
    "\t\t\ts = l[3].split(\":\")[1]\n",
    "\t\t\t#sr.append(s)\n",
    "\n",
    "\t\t\tr = l[4].split(\":\")[1]\n",
    "\t\t\t#rate.append(r)\n",
    "\n",
    "\t\t\tg = l[5].split(\":\")[1]\n",
    "\t\t\t#gr.append(g)\n",
    "\n",
    "\t\t\tlo = l[6].split(\":\")[1].split('\"')[1]\t\n",
    "\t\t\t#load.append(lo)\n",
    "\t\t\tfcsv.write(m+\",\"+t+\",\"+la+\",\"+s+\",\"+r+\",\"+g+\",\"+lo+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the JSON to CSV\n",
    "create_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will train the model offline in a py file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = client.query('SELECT label, sr, gs, load, timestamp FROM timeseriesdb.autogen.gear_metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96045"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results.raw['series'][0]['values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_classify = results.raw['series'][0]['values'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Metric  Timestamp  Label       SR  Rate        GR   Load\n",
      "0  offline          0      0  97656.0  25.0  0.840756  270.0\n",
      "1  offline          1      0  97656.0  25.0  0.515243  270.0\n",
      "2  offline          2      0  97656.0  25.0 -0.038345  270.0\n",
      "3  offline          3      0  97656.0  25.0  1.184862  270.0\n",
      "4  offline          4      0  97656.0  25.0  0.849715  270.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "gear_data=pd.read_csv(\"data/data_predict.csv\")\n",
    "print(gear_data.head())\n",
    "\n",
    "cols_to_norm = ['SR', 'GR','Load']\n",
    "\n",
    "gear_data[cols_to_norm] = gear_data[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "\n",
    "sr = tf.feature_column.numeric_column('SR')\n",
    "rate = tf.feature_column.numeric_column('Rate')\n",
    "gr = tf.feature_column.numeric_column('GR')\n",
    "load = tf.feature_column.numeric_column('Load')\n",
    "\n",
    "print(type(gear_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v1.keras.models' has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-be526abd8d4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dnn/models/trained_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v1.keras.models' has no attribute 'load'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
